{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train12_lgb = pd.read_csv('20180803\\\\data\\\\fenlei\\\\test_lable12_lgb.csv')\n",
    "train34_lgb = pd.read_csv('20180803\\\\data\\\\fenlei\\\\test_lable34_lgb.csv')\n",
    "train12_xgb = pd.read_csv('20180803\\\\data\\\\fenlei\\\\test_lable12_xgb.csv')\n",
    "train34_xgb = pd.read_csv('20180803\\\\data\\\\fenlei\\\\test_lable34_xgb.csv')\n",
    "train12_gb = pd.read_csv('20180803\\\\data\\\\fenlei\\\\test_lable12_gb.csv')\n",
    "train34_gb = pd.read_csv('20180803\\\\data\\\\fenlei\\\\test_lable34_gb.csv')\n",
    "train12_rf = pd.read_csv('20180803\\\\data\\\\fenlei\\\\test_lable12_rf.csv')\n",
    "train34_rf = pd.read_csv('20180803\\\\data\\\\fenlei\\\\test_lable34_rf.csv')\n",
    "train12_bagging = pd.read_csv('20180803\\\\data\\\\fenlei\\\\test_lable12_bagging.csv')\n",
    "train34_bagging = pd.read_csv('20180803\\\\data\\\\fenlei\\\\test_lable34_bagging.csv')\n",
    "train12_etc = pd.read_csv('20180803\\\\data\\\\fenlei\\\\test_lable12_etc.csv')\n",
    "train34_etc = pd.read_csv('20180803\\\\data\\\\fenlei\\\\test_lable34_etc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo12 = train12_lgb.merge(train12_xgb, on=['user_id'], how=\"left\")\n",
    "demo12 = demo12.merge(train12_gb, on=['user_id'], how=\"left\")\n",
    "demo12 = demo12.merge(train12_rf, on=['user_id'], how=\"left\")\n",
    "demo12 = demo12.merge(train12_bagging, on=['user_id'], how=\"left\")\n",
    "demo12 = demo12.merge(train12_etc, on=['user_id'], how=\"left\")\n",
    "demo12.columns = [\n",
    "                    'user_id','lgb','xgb','gb','rf','bagging','etc'\n",
    "                    ]\n",
    "demo12_ = demo12.iloc[:,1:].T\n",
    "toupiao = pd.DataFrame(demo12_.mean())\n",
    "toupiao.columns = ['jieguo']\n",
    "toupiao['user_id'] = demo12['user_id']\n",
    "toupiao['jieguo_2'] = toupiao['jieguo']\n",
    "del toupiao['jieguo']\n",
    "toupiao.rename(columns={'jieguo_2':'zhongshu'}, inplace = True)\n",
    "toupiao['zhongshu'] = toupiao.apply(lambda x: 2 if(x['zhongshu']>0.5) else 1,axis=1)\n",
    "demo12 = demo12.merge(toupiao, on=['user_id'], how=\"left\")\n",
    "demo12.to_csv(\"toupiaojieguo12.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "demo34 = train34_lgb.merge(train34_xgb, on=['user_id'], how=\"left\")\n",
    "demo34 = demo34.merge(train34_gb, on=['user_id'], how=\"left\")\n",
    "demo34 = demo34.merge(train34_rf, on=['user_id'], how=\"left\")\n",
    "demo34 = demo34.merge(train34_bagging, on=['user_id'], how=\"left\")\n",
    "#demo34 = demo34.merge(train34_etc, on=['user_id'], how=\"left\")\n",
    "demo34.columns = [\n",
    "                    'user_id','lgb','xgb','gb','rf','bagging'#,'etc'\n",
    "                    ]\n",
    "demo34_ = demo34.iloc[:,1:].T\n",
    "toupiao = pd.DataFrame(demo34_.mean())\n",
    "toupiao.columns = ['jieguo']\n",
    "toupiao['user_id'] = demo34['user_id']\n",
    "toupiao['jieguo_2'] = toupiao['jieguo']\n",
    "del toupiao['jieguo']\n",
    "toupiao.rename(columns={'jieguo_2':'zhongshu'}, inplace = True)\n",
    "toupiao['zhongshu'] = toupiao.apply(lambda x: 4 if(x['zhongshu']>0.5) else 3,axis=1)\n",
    "demo34 = demo34.merge(toupiao, on=['user_id'], how=\"left\")\n",
    "demo34.to_csv(\"toupiaojieguo34.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4146, 8)\n",
      "(15403, 8)\n",
      "(41, 7)\n",
      "(809344, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((19549, 8), (809385, 7))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lable1 = demo12[demo12['zhongshu']==1]\n",
    "lable1.to_csv(\"toupiaojieguo1_5.csv\",index=None)\n",
    "print lable1.shape\n",
    "lable2 = demo12[demo12['zhongshu']==2]\n",
    "lable2.to_csv(\"toupiaojieguo2_5.csv\",index=None)\n",
    "print lable2.shape\n",
    "lable3 = demo34[demo34['zhongshu']==3]\n",
    "lable3.to_csv(\"toupiaojieguo3.csv\",index=None)\n",
    "print lable3.shape\n",
    "lable4 = demo34[demo34['zhongshu']==4]\n",
    "lable4.to_csv(\"toupiaojieguo4.csv\",index=None)\n",
    "print lable4.shape\n",
    "demo12.shape,demo34.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3760, 7)\n",
    "(15789, 7)\n",
    "(41, 7)\n",
    "(809344, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     0\n",
       "2     1\n",
       "5     0\n",
       "9     1\n",
       "10    1\n",
       "11    0\n",
       "Name: lable, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['lable'][[0,1,2,5,9,10,11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042403</td>\n",
       "      <td>0.957597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.279144</td>\n",
       "      <td>0.720856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.254892</td>\n",
       "      <td>0.745108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.019043</td>\n",
       "      <td>0.980957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.019043</td>\n",
       "      <td>0.980957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.786046</td>\n",
       "      <td>0.213954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.021587</td>\n",
       "      <td>0.978413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.026965</td>\n",
       "      <td>0.973035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.453698</td>\n",
       "      <td>0.546302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.130113</td>\n",
       "      <td>0.869887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.012801</td>\n",
       "      <td>0.987199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.905367</td>\n",
       "      <td>0.094633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.015939</td>\n",
       "      <td>0.984061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.010908</td>\n",
       "      <td>0.989092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.016548</td>\n",
       "      <td>0.983452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.201367</td>\n",
       "      <td>0.798633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.035180</td>\n",
       "      <td>0.964820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.596443</td>\n",
       "      <td>0.403557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.832186</td>\n",
       "      <td>0.167814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.015939</td>\n",
       "      <td>0.984061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1\n",
       "0   0.042403  0.957597\n",
       "1   0.279144  0.720856\n",
       "2   0.254892  0.745108\n",
       "3   0.019043  0.980957\n",
       "4   0.019043  0.980957\n",
       "5   0.786046  0.213954\n",
       "6   0.021587  0.978413\n",
       "7   0.026965  0.973035\n",
       "8   0.453698  0.546302\n",
       "9   0.130113  0.869887\n",
       "10  0.012801  0.987199\n",
       "11  0.905367  0.094633\n",
       "12  0.015939  0.984061\n",
       "13  0.010908  0.989092\n",
       "14  0.016548  0.983452\n",
       "15  0.201367  0.798633\n",
       "16  0.035180  0.964820\n",
       "17  0.596443  0.403557\n",
       "18  0.832186  0.167814\n",
       "19  0.015939  0.984061"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从这里开始是每个分类器分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58233, 108)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_train_ = pd.read_csv(\"over_sampling_1.csv\")\n",
    "# data_train = pd.read_csv(\"pay_pricedengyu0.csv\")\n",
    "dt1=pd.to_datetime(data_train_[\"register_time\"])\n",
    "data_train_[\"register_time\"] = dt1.dt.dayofyear\n",
    "if \"prediction_pay_price\" in data_train_.columns:\n",
    "    data_train_ = data_train_.drop(\"prediction_pay_price\",axis=1) \n",
    "data_train_1 = data_train_.copy()\n",
    "data_train_ = data_train_.iloc[:,1:]\n",
    "data_train_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split   # cross_validation\n",
    "from sklearn.linear_model import RidgeClassifierCV,RidgeClassifier,LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier,AdaBoostClassifier,BaggingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import BernoulliNB,GaussianNB\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier,NearestCentroid,KNeighborsClassifier\n",
    "from sklearn.semi_supervised import LabelPropagation,LabelSpreading\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis,LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class add_feature(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, additional=1):\n",
    "        self.additional = additional\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X[\"shaman_rate\"] = X[\"shaman_reduce_value\"]/(X[\"shaman_add_value\"]+0.1)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    \n",
    "pipe = Pipeline([\n",
    "        ('add_feature', add_feature(additional=2))\n",
    "    ])\n",
    "\n",
    "data_train_ = pipe.fit_transform(data_train_)\n",
    "data_train_['lable_2'] = data_train_['lable']\n",
    "del data_train_['lable']\n",
    "data_train_.rename(columns={'lable_2':'lable'}, inplace = True)\n",
    "\n",
    "# data_train_.to_csv('tezhengceshi.csv',index=None)\n",
    "# data_train_['pvp_lanch*pay_count>mean'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train.drop(['user_id'],axis=1, inplace=True)\n",
    "# data_train = data_train_.iloc[:,1:]\n",
    "data_train = data_train_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((58233, 108), Index([u'lable'], dtype='object'))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = data_train.iloc[:, 0:len(data_train.columns)-1], data_train.iloc[:,len(data_train.columns)-1:]\n",
    "x.shape,y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def stacking(x_train, y_train, x_test, cv):\n",
    "\n",
    "#     le = LabelEncoder()\n",
    "#     y_train = le.fit_transform(y_train)\n",
    "\n",
    "    clfs = [\n",
    "        xgb.XGBClassifier(max_depth = 5),\n",
    "        lgb.LGBMClassifier(max_depth = 5),\n",
    "        RandomForestClassifier(max_depth = 6),\n",
    "        GradientBoostingClassifier(max_depth = 5),\n",
    "    ]\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=cv)\n",
    "    skf_dataset = list(skf.split(x_train, y_train))\n",
    "\n",
    "    # y_count: the kinds of labels\n",
    "    y_count = len(set(y_train.lable))\n",
    "#     print y_count\n",
    "    \n",
    "    # blend_train is the probabilities that every clf predicts every label (i.e. y) for every sample\n",
    "    # it is used to train the clfs in the second layer\n",
    "    blend_train = np.zeros((x_train.shape[0], len(clfs) * y_count))\n",
    "    blend_train = pd.DataFrame(blend_train)\n",
    "\n",
    "    # blend_test is used as the input of the clfs in the second layer to predict the labels of x_test\n",
    "    blend_test = np.zeros((x_test.shape[0], len(clfs) * y_count))\n",
    "    blend_test = pd.DataFrame(blend_test)\n",
    "\n",
    "    for j, clf in enumerate(clfs):\n",
    "        print j, clf\n",
    "\n",
    "        # blend_test_j: the probabilities that j-th clf predicts every label for x_test\n",
    "        blend_test_j = np.zeros((x_test.shape[0], len(skf_dataset) * y_count))\n",
    "        blend_test_j = pd.DataFrame(blend_test_j)\n",
    "        \n",
    "        for k, (train_idx, test_idx) in enumerate(skf_dataset):\n",
    "            x_train_k = x_train.iloc[train_idx,:]\n",
    "            y_train_k = y_train.iloc[train_idx,:]\n",
    "            x_train_holdout = x_train.iloc[test_idx,:]\n",
    "\n",
    "            clf.fit(x_train_k, y_train_k)\n",
    "            x_train_holdout_ = clf.predict_proba(x_train_holdout)\n",
    "            \n",
    "            #blend_train[test_idx, j*y_count: (j+1)*y_count] = clf.predict_proba(x_train_holdout)\n",
    "            blend_train.iloc[test_idx,j*y_count:(j+1)*y_count] = clf.predict_proba(x_train_holdout)\n",
    "            blend_test_j.iloc[:, k*y_count: (k+1)*y_count] = clf.predict_proba(x_test)\n",
    "\n",
    "        # because there are len(skf_dataset) blend_test_j for x_test, it needs to calculated the mean value\n",
    "        blend_test_j_mean = np.zeros((x_test.shape[0], y_count))\n",
    "        blend_test_j_mean = pd.DataFrame(blend_test_j_mean)\n",
    "\n",
    "        # indices: supposed y_count = 3, indices would be [0, 3, 6]\n",
    "        # it is used to find the corresponding probabilities of the same label, and calculate the mean\n",
    "        indices = np.arange(len(skf_dataset)) * y_count\n",
    "        for c in xrange(y_count):\n",
    "            blend_test_j_mean.iloc[:,c] = pd.DataFrame(blend_test_j.iloc[:, indices].mean(1))\n",
    "            indices += 1\n",
    "        blend_test[range(j*y_count,(j+1)*y_count)] = blend_test_j_mean\n",
    "#         print blend_test_j_mean.head()\n",
    "#         print blend_test.head()\n",
    "\n",
    "#     clf = LogisticRegression()\n",
    "#     clf.fit(blend_train, y_train)\n",
    "#     y_pred = clf.predict(blend_test)\n",
    "#     y_pred = le.inverse_transform(y_pred)\n",
    "\n",
    "    return blend_train,blend_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=5, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "1 LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        learning_rate=0.1, max_depth=5, min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=31, objective=None, random_state=None,\n",
      "        reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
      "        subsample_for_bin=200000, subsample_freq=0)\n",
      "2 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=6, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "3 GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=5,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "stacking_train,stacking_test = stacking(x,y,fit_data,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_train['user_id'] = data_train_1['user_id']\n",
    "stacking_test['user_id'] = all_test['user_id']\n",
    "stacking_train['lable'] = data_train_1['lable']\n",
    "stacking_train.to_csv('stacking_train12.csv',index=None)\n",
    "stacking_test.to_csv('stacking_test12.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   user_id  lable\n",
       " 0    14952    0.0\n",
       " 1    15029    0.0\n",
       " 2    15059    0.0\n",
       " 3    15064    0.0\n",
       " 4    15102    0.0, 5454.0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "stacking_train12 = pd.read_csv(\"stacking_train12.csv\")\n",
    "stacking_test12 = pd.read_csv(\"stacking_test12.csv\")\n",
    "stacking_train12_ = stacking_train12.iloc[:,:8]\n",
    "stacking_test12_ = stacking_test12.iloc[:,:8]\n",
    "# stacking_train12_.columns,stacking_test12_.columns\n",
    "lr = LogisticRegression()\n",
    "lr.fit(stacking_train12_, stacking_train12.lable)\n",
    "y_pred = lr.predict(stacking_test12_)\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "stacking_test12['lable'] = y_pred\n",
    "stacking_test12__ =stacking_test12.iloc[:,[8,9]]\n",
    "stacking_test12__.to_csv('stacking_test12_lr.csv',index=None)\n",
    "stacking_test12__.head(),stacking_test12__.lable.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_test12__ = pd.read_csv('stacking_test12_lr.csv')\n",
    "stacking_test12__['lable'] = stacking_test12__.apply(lambda x: 2 if(x['lable'] == 0) else 1,axis=1)   \n",
    "stacking_test12__.to_csv('stacking_test12_lr.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14095, 2)\n",
      "(5454, 2)\n"
     ]
    }
   ],
   "source": [
    "lable1 = stacking_test12__[stacking_test12__['lable']==2]\n",
    "print lable1.shape\n",
    "lable2 = stacking_test12__[stacking_test12__['lable']==1]\n",
    "print lable2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB Score=0.99794\n",
      "随机森林： 0.9979515420855278\n",
      "随机森林： 0.998058371702971\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=8, min_samples_split=5, oob_score=True)\n",
    "rf.fit(x_train, y_train)\n",
    "print u'OOB Score=%.5f' % rf.oob_score_\n",
    "y_train_pred = rf.predict(x_train)\n",
    "y_test_pred = rf.predict(x_test)\n",
    "print u'随机森林：', accuracy_score(y_train, y_train_pred)\n",
    "print u'随机森林：', accuracy_score(y_test, y_test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT： 0.9979951641793171\n",
      "GBDT： 0.9980370057794823\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(\n",
    "#     n_estimators=100, learning_rate=0.1, max_depth=5\n",
    ")\n",
    "gb.fit(x_train, y_train)\n",
    "y_train_pred = gb.predict(x_train)\n",
    "y_test_pred = gb.predict(x_test)\n",
    "print u'GBDT：', accuracy_score(y_train, y_train_pred)\n",
    "print u'GBDT：', accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid's auc: 0.85248\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[94]\tvalid's auc: 0.852651\n",
      "lgb： 0.8567015782614991\n",
      "lgb： 0.8089285714285714\n"
     ]
    }
   ],
   "source": [
    "def lightGBM(train_x,train_y,validation_x,validation_y):\n",
    "#     clf = lgb.LGBMClassifier(num_leaves= 127, \n",
    "#                              max_depth=10,\n",
    "#                              num_class=4,\n",
    "#                              silent=True,\n",
    "#                              metric='auc',\n",
    "#                              n_jobs=8, \n",
    "#                              n_estimators=1000,\n",
    "#                              colsample_bytree=0.9,\n",
    "#                              subsample=0.9,\n",
    "#                              learning_rate=0.01\n",
    "#                             )\n",
    "    clf = lgb.LGBMClassifier(\n",
    "#                             num_leaves= 127, \n",
    "#                              max_depth=8, \n",
    "#                              silent=True,\n",
    "#                              metric='auc',\n",
    "#                              n_jobs=8,\n",
    "#                              n_estimators=2000,\n",
    "#                              colsample_bytree=0.9,\n",
    "#                              subsample=0.9,\n",
    "#                              learning_rate=0.02\n",
    "                            )\n",
    "    \n",
    "    # clf.fit(train_x, train_y, **fit_params)\n",
    "    clf.fit(train_x,\n",
    "    train_y,\n",
    "    early_stopping_rounds=100,\n",
    "    eval_metric= 'auc', \n",
    "            eval_set = [(validation_x,validation_y)],\n",
    "            eval_names = ['valid'],\n",
    "            verbose= 100\n",
    "    )\n",
    "         \n",
    "    return clf\n",
    "\n",
    "clf = lightGBM(x_train,y_train, x_test, y_test)\n",
    "y_train_pred = clf.predict(x_train)\n",
    "y_test_pred = clf.predict(x_test)\n",
    "print u'lgb：', accuracy_score(y_train, y_train_pred)\n",
    "print u'lgb：', accuracy_score(y_test, y_test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtc： 0.9998477677951435\n",
      "dtc： 0.9957499617193871\n",
      "etc： 0.9998477677951435\n",
      "etc： 0.9980058471410614\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(x_train, y_train)\n",
    "y_train_pred = dtc.predict(x_train)\n",
    "y_test_pred = dtc.predict(x_test)\n",
    "print u'dtc：', accuracy_score(y_train, y_train_pred)\n",
    "print u'dtc：', accuracy_score(y_test, y_test_pred)                           \n",
    "                          \n",
    "\n",
    "etc = ExtraTreesClassifier()\n",
    "etc.fit(x_train, y_train)\n",
    "y_train_pred = etc.predict(x_train)\n",
    "y_test_pred = etc.predict(x_test)\n",
    "print u'etc：', accuracy_score(y_train, y_train_pred)\n",
    "print u'etc：', accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "参数alpha=1000.00\n",
      "Logistic回归： 0.9979266151747911\n",
      "Logistic回归： 0.9980227618304899\n"
     ]
    }
   ],
   "source": [
    "lr = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), cv=3)\n",
    "lr.fit(x_train, y_train)\n",
    "print u'参数alpha=%.2f' % lr.alpha_\n",
    "y_train_pred = lr.predict(x_train)\n",
    "y_test_pred = lr.predict(x_test)\n",
    "print u'Logistic回归：', accuracy_score(y_train, y_train_pred)\n",
    "print u'Logistic回归：', accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnb： 0.9089678122362643\n",
      "bnb： 0.9090043123555575\n"
     ]
    }
   ],
   "source": [
    "bnb = BernoulliNB()\n",
    "bnb.fit(x_train, y_train)\n",
    "y_train_pred = bnb.predict(x_train)\n",
    "y_test_pred = bnb.predict(x_test)\n",
    "print u'bnb：', accuracy_score(y_train, y_train_pred)\n",
    "print u'bnb：', accuracy_score(y_test, y_test_pred)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bayes： 0.9763817520769458\n",
      "bayes： 0.9768153022744026\n"
     ]
    }
   ],
   "source": [
    "bayes = GaussianNB() \n",
    "bayes.fit(x_train, y_train)\n",
    "y_train_pred = bayes.predict(x_train)\n",
    "y_test_pred = bayes.predict(x_test)\n",
    "print u'bayes：', accuracy_score(y_train, y_train_pred)\n",
    "print u'bayes：', accuracy_score(y_test, y_test_pred)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lp： 0.9999034702447029\n",
      "lp： 0.305984555984556\n"
     ]
    }
   ],
   "source": [
    "lp = LabelPropagation()#MemoryError\n",
    "lp.fit(x_train, y_train)\n",
    "y_train_pred = lp.predict(x_train)\n",
    "y_test_pred = lp.predict(x_test)\n",
    "print u'lp：', accuracy_score(y_train, y_train_pred)\n",
    "print u'lp：', accuracy_score(y_test, y_test_pred)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rc： 0.9979266151747911\n",
      "rc： 0.9980227618304899\n"
     ]
    }
   ],
   "source": [
    "rc=RidgeClassifier()\n",
    "rc.fit(x_train, y_train)\n",
    "y_train_pred = rc.predict(x_train)\n",
    "y_test_pred = rc.predict(x_test)\n",
    "print u'rc：', accuracy_score(y_train, y_train_pred)\n",
    "print u'rc：', accuracy_score(y_test, y_test_pred)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnc = RadiusNeighborsClassifier() #MemoryError\n",
    "rnc.fit(x_train, y_train)\n",
    "y_train_pred = rnc.predict(x_train)\n",
    "y_test_pred = rnc.predict(x_test)\n",
    "print u'rnc训练集准确率：', accuracy_score(y_train, y_train_pred)\n",
    "print u'rnc测试集准确率：', accuracy_score(y_test, y_test_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qda： 0.958458413010423\n",
      "qda： 0.9586676210112491\n"
     ]
    }
   ],
   "source": [
    "qda = QuadraticDiscriminantAnalysis() \n",
    "qda.fit(x_train, y_train)\n",
    "y_train_pred = qda.predict(x_train)\n",
    "y_test_pred = qda.predict(x_test)\n",
    "print u'qda：', accuracy_score(y_train, y_train_pred)\n",
    "print u'qda：', accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nc： 0.9693203143639543\n",
      "nc： 0.9695936201352463\n"
     ]
    }
   ],
   "source": [
    "nc = NearestCentroid() \n",
    "nc.fit(x_train, y_train)\n",
    "y_train_pred = nc.predict(x_train)\n",
    "y_test_pred = nc.predict(x_test)\n",
    "print u'nc：', accuracy_score(y_train, y_train_pred)\n",
    "print u'nc：', accuracy_score(y_test, y_test_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp： 0.9976310532331983\n",
      "mlp： 0.9977405535910776\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier() #准确率飘忽不定\n",
    "mlp.fit(x_train, y_train)\n",
    "y_train_pred = mlp.predict(x_train)\n",
    "y_test_pred = mlp.predict(x_test)\n",
    "print u'mlp：', accuracy_score(y_train, y_train_pred)\n",
    "print u'mlp：', accuracy_score(y_test, y_test_pred)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda： 0.9852619640269068\n",
      "lda： 0.9854604890659887\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis() \n",
    "lda.fit(x_train, y_train)\n",
    "y_train_pred = lda.predict(x_train)\n",
    "y_test_pred = lda.predict(x_test)\n",
    "print u'lda：', accuracy_score(y_train, y_train_pred)\n",
    "print u'lda：', accuracy_score(y_test, y_test_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls训练集准确率： 0.9999034702447029\n",
      "ls测试集准确率： 0.305984555984556\n"
     ]
    }
   ],
   "source": [
    "ls = LabelSpreading() #MemoryError \n",
    "ls.fit(x_train, y_train)\n",
    "y_train_pred = ls.predict(x_train)\n",
    "y_test_pred = ls.predict(x_test)\n",
    "print u'ls训练集准确率：', accuracy_score(y_train, y_train_pred)\n",
    "print u'ls测试集准确率：', accuracy_score(y_test, y_test_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn： 0.9979301761620392\n",
      "knn： 0.9979818104771366\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier() \n",
    "knn.fit(x_train, y_train)\n",
    "y_train_pred = knn.predict(x_train)\n",
    "y_test_pred = knn.predict(x_test)\n",
    "print u'knn：', accuracy_score(y_train, y_train_pred)\n",
    "print u'knn：', accuracy_score(y_test, y_test_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bagging： 0.9996875233689788\n",
      "bagging： 0.9979675665281442\n"
     ]
    }
   ],
   "source": [
    "bagging = BaggingClassifier()\n",
    "bagging.fit(x_train, y_train)\n",
    "y_train_pred = bagging.predict(x_train)\n",
    "y_test_pred = bagging.predict(x_test)\n",
    "print u'bagging：', accuracy_score(y_train, y_train_pred)\n",
    "print u'bagging：', accuracy_score(y_test, y_test_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ada： 0.9978990175236182\n",
      "Ada： 0.9980094081283095\n"
     ]
    }
   ],
   "source": [
    "Ada = AdaBoostClassifier()\n",
    "Ada.fit(x_train, y_train)\n",
    "y_train_pred = Ada.predict(x_train)\n",
    "y_test_pred = Ada.predict(x_test)\n",
    "print u'Ada：', accuracy_score(y_train, y_train_pred)\n",
    "print u'Ada：', accuracy_score(y_test, y_test_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svc： 0.9997586756117574\n",
      "svc： 0.7272200772200772\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(x_train, y_train)\n",
    "y_train_pred = svc.predict(x_train)\n",
    "y_test_pred = svc.predict(x_test)\n",
    "print u'svc：', accuracy_score(y_train, y_train_pred)\n",
    "print u'svc：', accuracy_score(y_test, y_test_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(809385, 108)\n",
      "(19549, 108)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test=pd.read_csv('test_pay_pricedayu0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19549, 107)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_data = all_test.iloc[:,1:108]\n",
    "dt1=pd.to_datetime(fit_data[\"register_time\"])\n",
    "fit_data[\"register_time\"] = dt1.dt.dayofyear\n",
    "fit_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_data = pipe.fit_transform(fit_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19549, 109)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(fit_data.values)\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "all_test['lable']=y_pred\n",
    "all_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'user_id', u'register_time', u'wood_add_value', u'wood_reduce_value',\n",
      "       u'stone_add_value', u'stone_reduce_value', u'ivory_add_value',\n",
      "       u'ivory_reduce_value', u'meat_add_value', u'meat_reduce_value',\n",
      "       ...\n",
      "       u'pvp_battle_count', u'pvp_lanch_count', u'pvp_win_count',\n",
      "       u'pve_battle_count', u'pve_lanch_count', u'pve_win_count',\n",
      "       u'avg_online_minutes', u'pay_price', u'pay_count', u'lable'],\n",
      "      dtype='object', length=109)\n",
      "Index([u'user_id', u'lable'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print all_test.columns\n",
    "all_test_ =all_test.iloc[:,[0,108]]\n",
    "print all_test_.columns\n",
    "all_test_.to_csv('test_lable12_svc.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 109)\n",
      "(19549, 109)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19549, 109)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lable_1 = all_test[all_test['lable'] == 1]\n",
    "lable_2 = all_test[all_test['lable'] == 0]\n",
    "print lable_2.shape\n",
    "print lable_1.shape\n",
    "all_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
