{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier,AdaBoostClassifier,BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((41439, 110),\n",
       " Index([u'user_id', u'register_time', u'wood_add_value', u'wood_reduce_value',\n",
       "        u'stone_add_value', u'stone_reduce_value', u'ivory_add_value',\n",
       "        u'ivory_reduce_value', u'meat_add_value', u'meat_reduce_value',\n",
       "        ...\n",
       "        u'pvp_lanch_count', u'pvp_win_count', u'pve_battle_count',\n",
       "        u'pve_lanch_count', u'pve_win_count', u'avg_online_minutes',\n",
       "        u'pay_price', u'pay_count', u'lable', u'leibie'],\n",
       "       dtype='object', length=110),\n",
       " (41439, 111),\n",
       " Index([u'user_id', u'register_time', u'wood_add_value', u'wood_reduce_value',\n",
       "        u'stone_add_value', u'stone_reduce_value', u'ivory_add_value',\n",
       "        u'ivory_reduce_value', u'meat_add_value', u'meat_reduce_value',\n",
       "        ...\n",
       "        u'pvp_win_count', u'pve_battle_count', u'pve_lanch_count',\n",
       "        u'pve_win_count', u'avg_online_minutes', u'pay_price', u'pay_count',\n",
       "        u'prediction_pay_price', u'lable', u'leibie'],\n",
       "       dtype='object', length=111))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"pay_pricedayu0.csv\")\n",
    "df[\"leibie\"] = 0\n",
    "df[\"leibie\"] = df.apply(lambda x: 1 if ((-x[\"pay_price\"] + x[\"prediction_pay_price\"])>=15 and  x[\"pay_price\"] != 0) else x[\"leibie\"] ,axis=1)\n",
    "df[\"leibie\"] = df.apply(lambda x: 2 if x[\"pay_price\"] == x[\"prediction_pay_price\"] else x[\"leibie\"],axis=1)\n",
    "df[\"leibie\"] = df.apply(lambda x: 3 if ((-x[\"pay_price\"]+x[\"prediction_pay_price\"])<15 and  x[\"pay_price\"] != 0 and (-x[\"pay_price\"]+x[\"prediction_pay_price\"])>0) else x[\"leibie\"],axis=1)\n",
    "df_ = df.drop(['prediction_pay_price'],axis=1)\n",
    "dt1=pd.to_datetime(df_[\"register_time\"])\n",
    "df_[\"register_time\"] = dt1.dt.dayofyear\n",
    "df_.shape,df_.columns,df.shape,df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def feature(df):\n",
    "#     df[\"wood\"] = df[\"wood_reduce_value\"]/(df[\"wood_add_value\"]+0.1)\n",
    "#     df[\"meat\"] = df[\"meat_reduce_value\"]/(df[\"meat_add_value\"]+0.1)\n",
    "#     df[\"ivory\"] = df[\"ivory_reduce_value\"]/(df[\"ivory_add_value\"]+0.1)\n",
    "#     df[\"stone\"] = df[\"stone_reduce_value\"]/(df[\"stone_add_value\"]+0.1)\n",
    "#     df[\"magic\"] = df[\"magic_reduce_value\"]/(df[\"magic_add_value\"]+0.1)    \n",
    "    \n",
    "#     df[\"general_acceleration\"] = df[\"general_acceleration_reduce_value\"]/(df[\"general_acceleration_add_value\"]+0.1)\n",
    "#     df[\"building_acceleration\"] = df[\"building_acceleration_reduce_value\"]/(df[\"building_acceleration_add_value\"]+0.1)\n",
    "    \n",
    "#     df[\"reaserch_acceleration\"] = df[\"reaserch_acceleration_reduce_value\"]/(df[\"reaserch_acceleration_add_value\"]+0.1)\n",
    "#     df[\"training_acceleration\"] = df[\"training_acceleration_reduce_value\"]/(df[\"training_acceleration_add_value\"]+0.1)\n",
    "    \n",
    "    \n",
    "#     df[\"sr_outpost\"] =df[\"sr_outpost_tier_3_level\"]+df[\"sr_outpost_tier_2_level\"]+df[\"sr_outpost_tier_4_level\"]\n",
    "#     df[\"pvp_battle\"] = df[\"pvp_battle_count\"]*df[\"pay_price\"]/df[\"avg_online_minutes\"]/df[\"pay_count\"]\n",
    "\n",
    "    \n",
    "#     df = df.drop([\n",
    "#                     'stone_reduce_value',    \n",
    "#                     ], axis=1)\n",
    "    \n",
    "#     return df\n",
    "# df = df.iloc[:,1:]\n",
    "# df = feature(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [x for x in df.columns if x not in [\"user_id\", 'register_time',\"leibie\",\"prediction_pay_price\",\"lable\"]]\n",
    "train_x = df[cols]\n",
    "train_y = df.iloc[:,110:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.4, random_state=2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = pd.read_csv(\"test_pay_pricedayu0.csv\")\n",
    "# x_test = X_test[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def stacking(x_train, y_train, x_test, cv):\n",
    "\n",
    "#     le = LabelEncoder()\n",
    "#     y_train = le.fit_transform(y_train)\n",
    "\n",
    "    clfs = [\n",
    "        xgb.XGBClassifier(max_depth = 5,booster= 'gbtree',objective='multi:softmax',gamma=0.1,n_estimators=300),\n",
    "        lgb.LGBMClassifier(max_depth = 5,objective='multi:softmax',n_estimators=300),\n",
    "        RandomForestClassifier(max_depth = 6,n_estimators=20),\n",
    "        GradientBoostingClassifier(max_depth = 5,n_estimators= 200),\n",
    "    ]\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=cv)\n",
    "    skf_dataset = list(skf.split(x_train, y_train))\n",
    "\n",
    "    # y_count: the kinds of labels\n",
    "    y_count = len(set(y_train.leibie))\n",
    "#     print y_count\n",
    "    \n",
    "    # blend_train is the probabilities that every clf predicts every label (i.e. y) for every sample\n",
    "    # it is used to train the clfs in the second layer\n",
    "    blend_train = np.zeros((x_train.shape[0], len(clfs) * y_count))\n",
    "    blend_train = pd.DataFrame(blend_train)\n",
    "\n",
    "    # blend_test is used as the input of the clfs in the second layer to predict the labels of x_test\n",
    "    blend_test = np.zeros((x_test.shape[0], len(clfs) * y_count))\n",
    "    blend_test = pd.DataFrame(blend_test)\n",
    "\n",
    "    for j, clf in enumerate(clfs):\n",
    "        print j, clf\n",
    "\n",
    "        # blend_test_j: the probabilities that j-th clf predicts every label for x_test\n",
    "        blend_test_j = np.zeros((x_test.shape[0], len(skf_dataset) * y_count))\n",
    "        blend_test_j = pd.DataFrame(blend_test_j)\n",
    "        \n",
    "        for k, (train_idx, test_idx) in enumerate(skf_dataset):\n",
    "            x_train_k = x_train.iloc[train_idx,:]\n",
    "            y_train_k = y_train.iloc[train_idx,:]\n",
    "            x_train_holdout = x_train.iloc[test_idx,:]\n",
    "\n",
    "            clf.fit(x_train_k, y_train_k)\n",
    "            x_train_holdout_ = clf.predict_proba(x_train_holdout)\n",
    "            \n",
    "            #blend_train[test_idx, j*y_count: (j+1)*y_count] = clf.predict_proba(x_train_holdout)\n",
    "            blend_train.iloc[test_idx,j*y_count:(j+1)*y_count] = clf.predict_proba(x_train_holdout)\n",
    "            blend_test_j.iloc[:, k*y_count: (k+1)*y_count] = clf.predict_proba(x_test)\n",
    "\n",
    "        # because there are len(skf_dataset) blend_test_j for x_test, it needs to calculated the mean value\n",
    "        blend_test_j_mean = np.zeros((x_test.shape[0], y_count))\n",
    "        blend_test_j_mean = pd.DataFrame(blend_test_j_mean)\n",
    "\n",
    "        # indices: supposed y_count = 3, indices would be [0, 3, 6]\n",
    "        # it is used to find the corresponding probabilities of the same label, and calculate the mean\n",
    "        indices = np.arange(len(skf_dataset)) * y_count\n",
    "        for c in xrange(y_count):\n",
    "            blend_test_j_mean.iloc[:,c] = pd.DataFrame(blend_test_j.iloc[:, indices].mean(1))\n",
    "            indices += 1\n",
    "        blend_test[range(j*y_count,(j+1)*y_count)] = blend_test_j_mean\n",
    "#         print blend_test_j_mean.head()\n",
    "#         print blend_test.head()\n",
    "\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(blend_train, y_train)\n",
    "    y_pred = clf.predict(blend_test)\n",
    "#     y_pred = le.inverse_transform(y_pred)\n",
    "\n",
    "    return y_pred#blend_train,blend_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0.1, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=5, min_child_weight=1, missing=None, n_estimators=300,\n",
      "       n_jobs=1, nthread=None, objective='multi:softmax', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-18867fc7764a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_test_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstacking\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# print u'stacking：', accuracy_score(y_test, y_test_pred)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# df.iloc[:,110:]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-4b272059b908>\u001b[0m in \u001b[0;36mstacking\u001b[1;34m(x_train, y_train, x_test, cv)\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mx_train_holdout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m             \u001b[0mx_train_holdout_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_holdout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\zhangzhenhua\\anaconda2.7\\lib\\site-packages\\xgboost\\sklearn.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set)\u001b[0m\n\u001b[0;32m    545\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m                               verbose_eval=verbose, xgb_model=None)\n\u001b[0m\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\zhangzhenhua\\anaconda2.7\\lib\\site-packages\\xgboost\\training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\zhangzhenhua\\anaconda2.7\\lib\\site-packages\\xgboost\\training.pyc\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\zhangzhenhua\\anaconda2.7\\lib\\site-packages\\xgboost\\core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m-> 1021\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1022\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y_test_pred = stacking(X_train,y_train,X_test,4)\n",
    "# print u'stacking：', accuracy_score(y_test, y_test_pred)\n",
    "# df.iloc[:,110:]\n",
    "\n",
    "\n",
    "# stacking_train['user_id'] = df['user_id']\n",
    "# stacking_test['user_id'] = X_test['user_id']\n",
    "# stacking_train['lable'] = df['lable']\n",
    "# # stacking_train.to_csv('stacking_train12.csv',index=None)\n",
    "# # stacking_test.to_csv('stacking_test12.csv',index=None)\n",
    "\n",
    "# stacking_train12 = stacking_train\n",
    "# stacking_test12 = stacking_test\n",
    "# stacking_train12_ = stacking_train12.iloc[:,:8]\n",
    "# stacking_test12_ = stacking_test12.iloc[:,:8]\n",
    "# # stacking_train12_.columns,stacking_test12_.columns\n",
    "# lr = LogisticRegression()\n",
    "# lr.fit(stacking_train12_, stacking_train12.lable)\n",
    "# y_pred = lr.predict(stacking_test12_)\n",
    "# y_pred = pd.DataFrame(y_pred)\n",
    "# stacking_test12['lable'] = y_pred\n",
    "# stacking_test12__ =stacking_test12.iloc[:,[8,9]]\n",
    "\n",
    "# stacking_test12__['lable'] = stacking_test12__.apply(lambda x: 2 if(x['lable'] == 0) else 1,axis=1)   \n",
    "# stacking_test12__.to_csv('stacking_test12_lr.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stacking："
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [16576, 19549]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-3dc35b39b962>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[1;34mu'stacking：'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\zhangzhenhua\\anaconda2.7\\lib\\site-packages\\sklearn\\metrics\\classification.pyc\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[0mdiffering_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_nonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\zhangzhenhua\\anaconda2.7\\lib\\site-packages\\sklearn\\metrics\\classification.pyc\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \"\"\"\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\zhangzhenhua\\anaconda2.7\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 204\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [16576, 19549]"
     ]
    }
   ],
   "source": [
    "# print u'stacking：', accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19549, (16576, 1), (19549, 106))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_test['pre'] = y_test_pred\n",
    "# lable1 = y_test[]\n",
    "len(y_test_pred),y_test.shape,x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16576, 106), (16576, 1))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
