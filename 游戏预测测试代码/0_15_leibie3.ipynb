{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction_pay_price减pay_price等于0、15为界把pay_price大于0的样本分为3类后，对第三类进行回归预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index([u'register_time', u'wood_add_value', u'wood_reduce_value',\n",
       "        u'stone_add_value', u'stone_reduce_value', u'ivory_add_value',\n",
       "        u'ivory_reduce_value', u'meat_add_value', u'meat_reduce_value',\n",
       "        u'magic_add_value',\n",
       "        ...\n",
       "        u'pvp_battle_count', u'pvp_lanch_count', u'pvp_win_count',\n",
       "        u'pve_battle_count', u'pve_lanch_count', u'pve_win_count',\n",
       "        u'avg_online_minutes', u'pay_price', u'pay_count', u'cha'],\n",
       "       dtype='object', length=108), (4615, 108))"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_train = pd.read_csv(\"label_3.csv\")\n",
    "data_train = data_train.iloc[:,:109]\n",
    "data_train_ = data_train.copy()\n",
    "dt1=pd.to_datetime(data_train[\"register_time\"])\n",
    "data_train[\"register_time\"] = dt1.dt.dayofyear\n",
    "# data_train = data_train.drop(\"user_id\",axis=1)\n",
    "data_train['cha'] = data_train['prediction_pay_price']-data_train['pay_price']\n",
    "data_train = data_train.drop([\"lable\",'prediction_pay_price'],axis=1)\n",
    "data_train.columns,data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # 用于数值计算\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split   # cross_validation\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "import gc\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "class add_feature(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, additional=1):\n",
    "        self.additional = additional\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "#         X[\"pujie_3\"] = (X[\"pve_lanch_count\"] + X[\"pve_win_count\"]) * X[\"pay_price\"]\n",
    "#         X[\"pve_pay_count\"] = X[\"pay_count\"] * (X[\"pve_lanch_count\"] + X[\"pve_win_count\"])\n",
    "\n",
    "#         X[\"day_in_year_1\"] = X[\"register_time\"] * X[\"pay_price\"]\n",
    "#         X[\"wkd\"] = dt1.dt.weekday\n",
    "#         X[\"wkd_1\"] = X[\"wkd\"] * X[\"pay_count\"]\n",
    "#         X[\"reaserch_acceleration\"] = X[\"reaserch_acceleration_add_value\"] - X[\"reaserch_acceleration_reduce_value\"]\n",
    "        \n",
    "#         X[\"meat\"] = X[\"meat_add_value\"] - X[\"meat_reduce_value\"]\n",
    "\n",
    "\n",
    "\n",
    "#         X = X.drop([\n",
    "#                     'meat_add_value',\n",
    "#                     'magic_add_value',\n",
    "#                     'magic_reduce_value',\n",
    "#                     'infantry_add_value',\n",
    "#                     'wound_infantry_add_value',\n",
    "#                     'wound_infantry_reduce_value',\n",
    "            \n",
    "#                     'sr_construction_speed_level',\n",
    "#                     'sr_hide_storage_level',\n",
    "#                     'sr_troop_consumption_level',\n",
    "#                     'sr_rss_a_prod_levell',\n",
    "#                     'sr_rss_b_prod_level',\n",
    "#                     'sr_rss_c_prod_level',\n",
    "#                     'sr_rss_d_prod_level',\n",
    "#                     'sr_rss_a_gather_level',\n",
    "#                     'sr_rss_e_gather_level',       \n",
    "\n",
    "#                     ], axis=1)\n",
    "        \n",
    "        \n",
    "        return X\n",
    "    \n",
    "\n",
    "pipe = Pipeline([\n",
    "        ('add_feature', add_feature(additional=2))\n",
    "    ])\n",
    "data_train = pipe.fit_transform(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4615, 107), Index([u'cha'], dtype='object'))"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['cha_2'] = data_train['cha']\n",
    "del data_train['cha']\n",
    "data_train.rename(columns={'cha_2':'cha'}, inplace = True)\n",
    "x_, y = data_train.iloc[:, 0:len(data_train.columns)-1], data_train.iloc[:,len(data_train.columns)-1:]\n",
    "x = StandardScaler().fit_transform(x_)\n",
    "x = pd.DataFrame(x)\n",
    "x.columns = x_.columns\n",
    "x.shape,y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb： 11.722638917526588\n",
      "xgb： 15.89374568843507\n",
      "xgb： 13.808644210539974\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(n_estimators=400, learning_rate=0.01,max_depth=4, random_state=1)\n",
    "xgb.fit(x_train, y_train)\n",
    "y_train_pred = xgb.predict(x_train)\n",
    "y_test_pred = xgb.predict(x_test)\n",
    "y_pred = xgb.predict(x)\n",
    "print u'xgb：', mean_squared_error(y_train, y_train_pred)\n",
    "print u'xgb：', mean_squared_error(y_test, y_test_pred)\n",
    "print u'xgb：', mean_squared_error(y, y_pred)\n",
    "# y_ = y.copy()\n",
    "# y_['y_pred'] = y_pred\n",
    "# y_['pay_price'] = x_test['pay_price']\n",
    "# y_.to_csv('xgb.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbdt： 11.761403436457304\n",
      "gbdt： 16.289564545403607\n",
      "gbdt： 14.025974582599897\n"
     ]
    }
   ],
   "source": [
    "gbdt = GradientBoostingRegressor(n_estimators=400, learning_rate=0.01,max_depth=4, random_state=0, loss='ls',)\n",
    "gbdt.fit(x_train, y_train)\n",
    "y_train_pred = gbdt.predict(x_train)\n",
    "y_test_pred = gbdt.predict(x_test)\n",
    "y_pred = gbdt.predict(x)\n",
    "print u'gbdt：', mean_squared_error(y_train, y_train_pred)\n",
    "print u'gbdt：', mean_squared_error(y_test, y_test_pred)\n",
    "print u'gbdt：', mean_squared_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's l1: 3.3602\n",
      "lgb： 11.5508343062233\n",
      "lgb： 16.2155520422159\n",
      "lgb： 13.88369856075654\n"
     ]
    }
   ],
   "source": [
    "y_train_ = y_train['cha'].values\n",
    "y_test_ = y_test['cha'].values\n",
    "X_train = x_train.values\n",
    "X_test = x_test.values\n",
    "\n",
    "lgb = LGBMRegressor(objective='regression',num_leaves=63,learning_rate=0.05,n_estimators=200)\n",
    "lgb.fit(X_train, y_train,eval_set=[(X_test, y_test_)],eval_metric='l1',early_stopping_rounds=10,verbose =50,)\n",
    "y_train_pred = lgb.predict(x_train)\n",
    "y_test_pred = lgb.predict(x_test)\n",
    "y_pred = lgb.predict(x)\n",
    "print u'lgb：', mean_squared_error(y_train_, y_train_pred)\n",
    "print u'lgb：', mean_squared_error(y_test_, y_test_pred)\n",
    "print u'lgb：', mean_squared_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index([u'register_time', u'wood_add_value', u'wood_reduce_value',\n",
       "        u'stone_add_value', u'stone_reduce_value', u'ivory_add_value',\n",
       "        u'ivory_reduce_value', u'meat_add_value', u'meat_reduce_value',\n",
       "        u'magic_add_value',\n",
       "        ...\n",
       "        u'sr_rss_help_bonus_level', u'pvp_battle_count', u'pvp_lanch_count',\n",
       "        u'pvp_win_count', u'pve_battle_count', u'pve_lanch_count',\n",
       "        u'pve_win_count', u'avg_online_minutes', u'pay_price', u'pay_count'],\n",
       "       dtype='object', length=107), (144, 107))"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_csv(\"test_label3_7.csv\")\n",
    "data_test = data_test.iloc[:,:108]\n",
    "data_test_ = data_test.copy()\n",
    "dt1=pd.to_datetime(data_test[\"register_time\"])\n",
    "data_test[\"register_time\"] = dt1.dt.dayofyear\n",
    "# data_test.drop(['zhongshu',\"user_id\",'prediction_pay_price',],axis=1, inplace=True)\n",
    "data_test.drop([\"user_id\"],axis=1, inplace=True)\n",
    "data_test.columns,data_test.shape\n",
    "# xgb.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index([u'user_id', u'prediction_pay_price'], dtype='object'), (144, 2))"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_test = pipe.fit_transform(data_test)\n",
    "test_pred_xgb = xgb.predict(data_test)\n",
    "# test_pred_lgb = lgb.predict(data_test)\n",
    "# test_pred_gbdt = gbdt.predict(data_test)\n",
    "test_pred_ = data_test_.iloc[:,:1]\n",
    "test_pred_['pre_xgb'] = test_pred_xgb\n",
    "test_pred_['pre_xgb'] = test_pred_.apply(lambda x: 14.98 if (x['pre_xgb']>=11.09) else x['pre_xgb'] ,axis=1)\n",
    "test_pred_['pre_xgb'] = test_pred_.apply(lambda x: 1.99 if (x['pre_xgb']<=3.0) else x['pre_xgb'] ,axis=1)\n",
    "# test_pred_['pre_lgb'] = test_pred_lgb\n",
    "# test_pred_['pre_lgb'] = test_pred_.apply(lambda x: 14.98 if (x['pre_lgb']>=11.09) else x['pre_lgb'] ,axis=1)\n",
    "# test_pred_['pre_lgb'] = test_pred_.apply(lambda x: 1.99 if (x['pre_lgb']<=3.0) else x['pre_lgb'] ,axis=1)\n",
    "# test_pred_['pre_gbdt'] = test_pred_gbdt\n",
    "# test_pred_['pre_gbdt'] = test_pred_.apply(lambda x: 14.98 if (x['pre_gbdt']>=11.09) else x['pre_gbdt'] ,axis=1)\n",
    "# test_pred_['pre_gbdt'] = test_pred_.apply(lambda x: 1.99 if (x['pre_gbdt']<=3.0) else x['pre_gbdt'] ,axis=1)\n",
    "test_pred_['pay_price'] = data_test_['pay_price']\n",
    "test_pred_['prediction_pay_price'] = test_pred_['pay_price']+test_pred_['pre_xgb']\n",
    "# test_pred_['prediction_pay_price_xgb'] = test_pred_['pay_price']+test_pred_['pre_xgb']\n",
    "# test_pred_['prediction_pay_price_lgb'] = test_pred_['pay_price']+test_pred_['pre_lgb']\n",
    "# test_pred_['prediction_pay_price_gbdt'] = test_pred_['pay_price']+test_pred_['pre_gbdt']\n",
    "# test_pred_['prediction_pay_price']=(test_pred_['prediction_pay_price_xgb']+test_pred_['prediction_pay_price_lgb']+test_pred_['prediction_pay_price_gbdt'])/3\n",
    "# test_pred_['yuanlai_prediction_pay_price'] = data_test_['prediction_pay_price']\n",
    "test_pred_ = test_pred_.iloc[:,[0,3]]\n",
    "test_pred_.to_csv('leibie3_0829.csv',index=None)\n",
    "test_pred_.columns,test_pred_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best parameters found by grid search are:', {'max_depth': 1})\n"
     ]
    }
   ],
   "source": [
    "estimator = XGBRegressor(num_leaves=63)\n",
    " \n",
    "param_grid = {\n",
    "    'max_depth': [2,3,1],\n",
    "}\n",
    " \n",
    "gscv = GridSearchCV(estimator, param_grid, cv = 3, scoring=\"neg_mean_squared_error\")\n",
    " \n",
    "gscv.fit(x_train, y_train)\n",
    " \n",
    "print('Best parameters found by grid search are:', gscv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.053273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.048209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.038267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.038079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.029450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.028888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.027012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.026074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.025699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.022697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.022510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.021760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.020822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.020822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.020446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.019696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.018946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.018758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.017820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.017445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.017445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.017445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.016882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.016320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.015757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.015382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.015007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.014444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.000750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.000375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.000375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.000188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feature_Importance\n",
       "105            0.053273\n",
       "5              0.048209\n",
       "104            0.038267\n",
       "16             0.038079\n",
       "23             0.029450\n",
       "1              0.028888\n",
       "25             0.027012\n",
       "98             0.026074\n",
       "7              0.025699\n",
       "13             0.022697\n",
       "3              0.022510\n",
       "32             0.021760\n",
       "87             0.020822\n",
       "99             0.020822\n",
       "11             0.020446\n",
       "9              0.019696\n",
       "8              0.018946\n",
       "33             0.018758\n",
       "85             0.017820\n",
       "101            0.017445\n",
       "12             0.017445\n",
       "15             0.017445\n",
       "71             0.016882\n",
       "30             0.016320\n",
       "31             0.015757\n",
       "28             0.015382\n",
       "29             0.015007\n",
       "102            0.014444\n",
       "4              0.014256\n",
       "2              0.014256\n",
       "..                  ...\n",
       "83             0.000750\n",
       "75             0.000375\n",
       "79             0.000375\n",
       "84             0.000188\n",
       "70             0.000000\n",
       "60             0.000000\n",
       "95             0.000000\n",
       "96             0.000000\n",
       "97             0.000000\n",
       "58             0.000000\n",
       "59             0.000000\n",
       "93             0.000000\n",
       "57             0.000000\n",
       "52             0.000000\n",
       "51             0.000000\n",
       "94             0.000000\n",
       "61             0.000000\n",
       "92             0.000000\n",
       "91             0.000000\n",
       "90             0.000000\n",
       "62             0.000000\n",
       "86             0.000000\n",
       "63             0.000000\n",
       "64             0.000000\n",
       "65             0.000000\n",
       "66             0.000000\n",
       "67             0.000000\n",
       "68             0.000000\n",
       "69             0.000000\n",
       "0              0.000000\n",
       "\n",
       "[107 rows x 1 columns]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = pd.DataFrame(xgb.feature_importances_ )\n",
    "importance.index = x.columns\n",
    "importance.columns = ['Feature_Importance']\n",
    "importance.sort_values(\"Feature_Importance\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_ = y.copy()\n",
    "# y_['y_pred'] = y_pred\n",
    "# y_.to_csv('gbdt1.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction_pay_price减pay_price等于0、15为界把pay_price大于0的样本分为3类后，对第三类进行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index([u'user_id', u'register_time', u'wood_add_value', u'wood_reduce_value',\n",
       "        u'stone_add_value', u'stone_reduce_value', u'ivory_add_value',\n",
       "        u'ivory_reduce_value', u'meat_add_value', u'meat_reduce_value',\n",
       "        ...\n",
       "        u'pvp_battle_count', u'pvp_lanch_count', u'pvp_win_count',\n",
       "        u'pve_battle_count', u'pve_lanch_count', u'pve_win_count',\n",
       "        u'avg_online_minutes', u'pay_price', u'pay_count', u'cha'],\n",
       "       dtype='object', length=109), (4615, 109))"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_train = pd.read_csv(\"leibie3.csv\")\n",
    "data_train_ = data_train.copy()\n",
    "data_train.columns,data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # 用于数值计算\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score,mean_squared_error\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split   # cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import gc\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_train[\"leibie\"] = 0\n",
    "data_train[\"leibie\"] = data_train.apply(lambda x: 3 if (x[\"cha\"]>=14) else x[\"leibie\"] ,axis=1)#14.99\n",
    "data_train[\"leibie\"] = data_train.apply(lambda x: 2 if (x[\"cha\"]<14 and x[\"cha\"]>=9.5) else x[\"leibie\"],axis=1)#9.99\n",
    "data_train[\"leibie\"] = data_train.apply(lambda x: 1 if (x[\"cha\"]<9.5 and x[\"cha\"]>=2.5) else x[\"leibie\"],axis=1)#4.99\n",
    "# data_train[\"leibie\"] = data_train.apply(lambda x: 0 if (x[\"cha\"]<3) else x[\"leibie\"],axis=1)#1.99\n",
    "data_train = data_train.drop(['user_id','cha'],axis=1)\n",
    "# data_train.head()\n",
    "# data_train.to_csv('leibie3_fenlei.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "class add_feature(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, additional=1):\n",
    "        self.additional = additional\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "#         X[\"wood\"] = X[\"wood_reduce_value\"]/(X[\"wood_add_value\"]+0.1)\n",
    "#         X[\"meat\"] = X[\"meat_reduce_value\"]/(X[\"meat_add_value\"]+0.1)\n",
    "#         X[\"magic\"] = X[\"magic_reduce_value\"]/(X[\"magic_add_value\"]+0.1)\n",
    "        X[\"shaman_rate\"] = X[\"shaman_reduce_value\"]/(X[\"shaman_add_value\"]+0.1)\n",
    "\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    \n",
    "pipe = Pipeline([\n",
    "        ('add_feature', add_feature(additional=2))\n",
    "    ])\n",
    "data_train_ = pipe.fit_transform(data_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4615, 107), Index([u'leibie'], dtype='object'))"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = data_train.iloc[:, 0:len(data_train.columns)-1], data_train.iloc[:,len(data_train.columns)-1:]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1, test_size=0.5)\n",
    "x.shape,y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb： 0.9969657563935848\n",
      "xgb： 0.42980935875216636\n",
      "xgb： 0.7133261105092091\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(booster= 'gbtree',\n",
    "                      objective='multi:softmax',  # 多分类的问题\n",
    "                              num_class= 4,\n",
    "                              gamma=0.1,                  # 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。\n",
    "                              max_depth= 12,               # 构建树的深度，越大越容易过拟合\n",
    "                              # \"lambda\" = 2,                   # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。\n",
    "                              subsample= 0.7,              # 随机采样训练样本\n",
    "                              colsample_bytree= 0.7,       # 生成树时进行的列采样\n",
    "                              min_child_weight= 3,\n",
    "                              silent=1,                   # 设置成1则没有运行信息输出，最好是设置为0.\n",
    "                              eta=0.001,                  # 如同学习率\n",
    "                              seed= 1000,\n",
    "                              nthread= 4,\n",
    "                              n_estimators=500,\n",
    "                              learning_rate=0.01,\n",
    "                   )\n",
    "xgb.fit(x_train, y_train)\n",
    "y_train_pred = xgb.predict(x_train)\n",
    "y_test_pred = xgb.predict(x_test)\n",
    "y_pred = xgb.predict(x)\n",
    "print u'xgb：', accuracy_score(y_train, y_train_pred)\n",
    "print u'xgb：', accuracy_score(y_test, y_test_pred)\n",
    "print u'xgb：', accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb： 2300 2307\n",
      "xgb： 992 2308\n",
      "xgb： 3292 4615\n"
     ]
    }
   ],
   "source": [
    "y_train_ = y_train.copy()\n",
    "y_train_['pre'] = y_train_pred\n",
    "# sum(y_train_['pre'] == y_train_['leibie'])\n",
    "y_test_ = y_test.copy()\n",
    "y_test_['pre'] = y_test_pred\n",
    "# sum(y_test_['pre'] == y_test_['leibie'])\n",
    "y_ = y.copy()\n",
    "y_['pre'] = y_pred\n",
    "# sum(y_['pre'] == y_['leibie'])\n",
    "print u'xgb：', sum(y_train_['pre'] == y_train_['leibie']),len(y_train_.index)\n",
    "print u'xgb：', sum(y_test_['pre'] == y_test_['leibie']),len(y_test_.index)\n",
    "print u'xgb：', sum(y_['pre'] == y_['leibie']),len(y_.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test_['pre_cha'] = 1.99  \n",
    "y_test_['pre_cha'] = y_test_.apply(lambda x: 14.99 if (x[\"pre\"] == 3) else x[\"pre_cha\"] ,axis=1)#14.99\n",
    "y_test_['pre_cha'] = y_test_.apply(lambda x: 9.99 if (x[\"pre\"] == 2) else x[\"pre_cha\"] ,axis=1)#9.99\n",
    "y_test_['pre_cha'] = y_test_.apply(lambda x: 4.99 if (x[\"pre\"] == 1) else x[\"pre_cha\"] ,axis=1)#4.99\n",
    "y_test_['cha'] = data_train_['cha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.594576733102254"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test_['cha'],y_test_['pre_cha'])\n",
    "# y_test_.to_csv('leibie3_fenlei.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.36074880823402"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "19.40950287107259\n",
    "19.36074880823402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
